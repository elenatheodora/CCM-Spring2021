{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework - Bayesian modeling - Part A (95 points)\n",
    "## Bayesian concept learning with the number game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by *Brenden Lake* and *Todd Gureckis*  \n",
    "Computational Cognitive Modeling  \n",
    "NYU class webpage: https://brendenlake.github.io/CCM-site/  \n",
    "email to course instructors: instructors-ccm-spring2020@nyuccl.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "This homework is due before midnight on Monday, March 29. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will get hands on experience with Bayesian concept learning and the \"number game,\" as covered in lecture. As with so many of our everyday inferences, the data we receive is far too sparse and noisy to be conclusive. Nevertheless, people must make generalizations and take actions based on imperfect and insufficient data. In data science and machine learning, the situation is often the same: the data is not enough to produce an answer with certainty, yet we can make meaningful generalizations anyway. What computational mechanisms can support these types of inferences?\n",
    "\n",
    "The number game is a quintessential inductive problem. In the number game, there is an unknown computer program that generates numbers in the range 1 to 100. You are provided with a small set of random examples from this program. For instance, in the figure below, you get two random examples from the program: the numbers '8' and '2'.\n",
    "\n",
    "<img src=\"images/number_game_comp.jpeg\" style=\"width: 300px;\"/>\n",
    "\n",
    "Which numbers will also be accepted by the same program? Of course, it depends what the program is, and you don't have enough information to be sure. Should '9' be accepted? Perhaps, if the concept is \"all numbers up to 10.\" What about '10'? A better candidate, since the program could again be \"numbers up to 10\", or \"all even numbers.\" What about '16'? This is another good candidate, and the program \"powers of 2\" is also consistent with the examples so far. How should one generalize based on the evidence so far? This homework explores how the Bayesian framework provides an answer to this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The number game was introduced in the following paper:\n",
    "<ul>\n",
    "<li>Tenenbaum, J. B. (2000). Rules and similarity in concept learning. In Advances in Neural Information Processing Systems (NIPS).</li>\n",
    "</ul>\n",
    "This is assignment is adapted from exercises developed by Josh Tenenbaum.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bayesian model\n",
    "In the number game, we receive a set of $n$ positive examples $X = \\{x^{(1)},...,x^{(n)}\\}$ of an unknown concept $C$. In a Bayesian analysis of the task, the goal is predict $P(y \\in C\\ |\\ X)$, which is the probability that a new number $y$ is also a member of the concept $C$ after receiving the set of examples $X$.\n",
    "\n",
    "#### Updating beliefs with Bayes' rule\n",
    "Let's proceed with the Bayesian model of the task. There is a hypothesis space $H$ of concepts, where a particular member of the hypothesis space (i.e., a particular concept) is denoted $h \\in H$. The Bayesian model includes a prior distribution $P(h)$ over the hypotheses and a likelihood $P(X|h)$. Bayes' rule specifies how to compute the posterior distribution over hypotheses given these two pieces:\n",
    "\\begin{equation}\n",
    "P(h|X) = \\frac{P(X|h)P(h)}{\\sum_{h' \\in H} P(X|h')P(h')}\n",
    "\\end{equation}\n",
    "The likelihood is specified below. We will leave the prior to later.\n",
    "\n",
    "#### Likelihood\n",
    "We assume that each number in $X$ is an independent sample from the set of all valid numbers. Thus, the likelihood decomposes as a product of individual probabilities,\n",
    "\\begin{equation}\n",
    "P(X|h) = \\prod_{i=1}^n P(x^{(i)}|h).\n",
    "\\end{equation}\n",
    "We assume that the numbers are sampled uniformly at random from the set of valid numbers, such that $P(x^{(i)}|h) = \\frac{1}{|h|}$ if $x^{(i)} \\in h$ and $P(x^{(i)}|h) = 0$ otherwise. The term $|h|$ is the cardinality or set size of the hypothesis $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 1 (10 points) </h3>\n",
    "<br>\n",
    "Let's compute a very simple posterior distribution by hand. Assume there are only two possible hypotheses:\n",
    "<ul>\n",
    "    <li>multiples of 10 ($h_1$)</li>\n",
    "    <li>even numbers ($h_2$)</li>\n",
    "</ul>\n",
    "<br>\n",
    "which are equally likely in the prior. Only the numbers 1 through 100 are possible. The positive examples $X$ consist of just 10 and 30. What is the posterior probability of each hypothesis? Please **show your work** in the cell below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior Probability\n",
    "\n",
    "\\begin{equation}\n",
    "P(h1|X) = \\frac{P(X|h1)P(h1)}{\\sum_{h' \\in H} P(X|h1')P(h1')} = \\frac{P(X|h1)P(h1)}{P(X|h1)P(h1) + P(X|h2)P(h2)}\\\\\n",
    "P(h1)=P(h2)\\\\\n",
    "\\\\\n",
    "P(h1|X)=\\frac{P(X|h1)}{P(X|h1)+P(X|h2)}\\\\\n",
    "P(h1|X)=\\frac{0.01}{0.01+0.0004}\\\\\n",
    "P(h1|X)=0.9615 \\\\\n",
    "P(h2|X)=0.0384\\\\\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making posterior predictions\n",
    "Once we have the posterior beliefs over hypotheses, we want to be able to make predictions about the membership of a new number $y$ in the concept $C$, or as mentioned $P(y \\in C\\ |\\ X)$. To compute this, we average over all possible hypotheses weighted by the posterior probability,\n",
    "\n",
    "\\begin{equation}\n",
    "P(y \\in C\\ |\\ X) = \\sum_{h \\in H} P(y \\in C\\ |\\ h) P(h|X),\n",
    "\\end{equation}\n",
    "\n",
    "where the first term is simply $1$ or $0$ based on the membership of $y$ in h, and the second term is the posterior weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 2 (10 points) </h3>\n",
    "<br>\n",
    "Now let's manually compute some predictions.\n",
    "<ul>\n",
    "<li> Given the posterior distribution computed in Problem 1, what is the probability that `40` is also a member of the concept? </li> \n",
    "<li> Given the same posterior, what is the probability that `4` is also a member of the concept? </li> \n",
    "</ul>\n",
    "<br>\n",
    "Please **show your work** in the cell below. Your answers from Problem 1 will help you.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(40 \\in C |X)=P(40 \\in C|h1)P(h1|X)+P(40 \\in C|h2)P(h2|X)\\\\\n",
    "We take the values of P(h1|X) and P(h2|X) from problem 1\\\\\n",
    "P(40 \\in C |X)=1*0.9615+1*0.0384=1\\\\\n",
    "P(4 \\in C |X)=P(4 \\in C|h1)P(h1|X)+P(4 \\in C|h2)P(h2|X)\\\\\n",
    "P(4 \\in C |X)=0*0.9615+1*0.0384=0.0384\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation - Hypothesis space and prior\n",
    "Let's dive into the implementation of the number game. First, let's import some packages and helpful functions.\n",
    "\n",
    "`x_all` is the list of all possible numbers. We include 0 as a possible number for programming convenience, although none of the hypotheses include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "x_max = 100 # maximum number allowed\n",
    "x_all = np.arange(0,x_max+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypothesis space $H$ includes two main kinds of hypotheses. The first kind consists of mathematical hypotheses such as odd numbers, even numbers, square numbers, cube numbers, primes, multiples of $n$, powers of $n$, and numbers ending with a particular digit. The second kind consists of interval hypotheses, which are solid intervals of numbers, such as $12, 13, 14, 15, 16, 17$. Each hypothesis will be represented as a list of the numbers that fit that hypothesis. The free parameters `mylambda` controls how much of the prior is specified by each type of hypothesis, with `mylambda` weight going to the mathematical hypotheses and `1-mylambda` weights going to the interval hypotheses.\n",
    "\n",
    "The code below shows how to generate the mathematical hypotheses and their prior probabilities (in natural log space).  To keep the prior simple, each mathematical hypothesis is given equal weight in the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Four examples of math hypotheses:\n",
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99]\n",
      "\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100]\n",
      "\n",
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "\n",
      "[1, 8, 27, 64]\n",
      "\n",
      "Their prior log-probabilities:\n",
      "[-3.93182563 -3.93182563 -3.93182563 -3.93182563]\n"
     ]
    }
   ],
   "source": [
    "def make_h_odd():\n",
    "    return list(range(1,x_max+1,2))\n",
    "\n",
    "def make_h_even():\n",
    "    return list(range(2,x_max+1,2))\n",
    "\n",
    "def make_h_square():\n",
    "    h = []\n",
    "    for x in range(1,x_max+1):\n",
    "        if x**2 <= x_max:\n",
    "            h.append(x**2)\n",
    "    return h\n",
    "\n",
    "def make_h_cube():\n",
    "    h = []\n",
    "    for x in range(1,x_max+1):\n",
    "        if x**3 <= x_max:\n",
    "            h.append(x**3)\n",
    "    return h\n",
    "\n",
    "def make_h_primes():\n",
    "    return [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n",
    "\n",
    "def make_h_mult_of_y(y):\n",
    "    h = []\n",
    "    for x in range(1,x_max+1):\n",
    "        if x*y <= x_max:\n",
    "            h.append(x*y)\n",
    "    return h\n",
    "\n",
    "def make_h_powers_of_y(y):\n",
    "    h = []\n",
    "    for x in range(1,x_max+1):\n",
    "        if y**x <= x_max:\n",
    "            h.append(y**x)\n",
    "    return h\n",
    "\n",
    "def make_h_numbers_ending_in_y(y):\n",
    "    h = []\n",
    "    for x in range(1,x_max+1):\n",
    "        if str(x)[-1] == str(y):\n",
    "            h.append(x)\n",
    "    return h\n",
    "\n",
    "def generate_math_hypotheses(mylambda):\n",
    "    h_set = [make_h_odd(), make_h_even(), make_h_square(), make_h_cube(), make_h_primes()]\n",
    "    h_set += [make_h_mult_of_y(y) for y in range(3,13)]\n",
    "    h_set += [make_h_powers_of_y(y) for y in range(2,11)]\n",
    "    h_set += [make_h_numbers_ending_in_y(y) for y in range(0,10)]\n",
    "    n_hyp = len(h_set)\n",
    "    log_prior = np.log(mylambda * np.ones(n_hyp) / float(n_hyp))\n",
    "    return h_set, log_prior\n",
    "\n",
    "h_set_math, log_prior_math = generate_math_hypotheses(2./3)\n",
    "print(\"Four examples of math hypotheses:\")\n",
    "for i in range(4):\n",
    "    print(h_set_math[i])\n",
    "    print(\"\")\n",
    "print(\"Their prior log-probabilities:\")\n",
    "print(log_prior_math[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All possible interval hypotheses and their prior probabilities can be generated with the following code. All interval hypotheses are not equally likely in the prior, and following Tenenbaum's specification, we use an Erlang distribution with parameter `sigma=10` to express an expectation for intermediate-sized hypotheses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Four examples of interval hypotheses\n",
      "[1]\n",
      "\n",
      "[1, 2]\n",
      "\n",
      "[1, 2, 3]\n",
      "\n",
      "[1, 2, 3, 4]\n",
      "\n",
      "Their prior log-probabilities:\n",
      "[-10.197254    -9.60410682  -9.29864171  -9.11095964]\n"
     ]
    }
   ],
   "source": [
    "def make_h_between_y_and_z(y,z):\n",
    "    assert(y >= 1 and z <= x_max)\n",
    "    return list(range(y,z+1))\n",
    "\n",
    "def pdf_erlang(x,sigma=10.):\n",
    "    return (x / sigma**2) * np.exp(-x/sigma)\n",
    "\n",
    "def generate_interval_hypotheses(mylambda):\n",
    "    h_set = []\n",
    "    for y in range(1,x_max+1):\n",
    "        for z in range(y,x_max+1):            \n",
    "            h_set.append(make_h_between_y_and_z(y,z))\n",
    "    nh = len(h_set)\n",
    "    pv = np.ones(nh)\n",
    "    for idx,h in enumerate(h_set): # prior based on length\n",
    "        pv[idx] = pdf_erlang(len(h))\n",
    "    pv = pv / np.sum(pv)\n",
    "    pv = (1-mylambda) * pv\n",
    "    log_prior = np.log(pv)\n",
    "    return h_set, log_prior\n",
    "\n",
    "h_set_int, log_prior_int = generate_interval_hypotheses(2./3)\n",
    "print(\"Four examples of interval hypotheses\")\n",
    "for i in range(4):\n",
    "    print(h_set_int[i])\n",
    "    print(\"\")\n",
    "print(\"Their prior log-probabilities:\")\n",
    "print(log_prior_int[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Together, we can define a `generate_hypotheses` function that uses all of this code to generate the complete set of hypotheses and their prior probabilities. We also use `convert_h_list_to_numpy` to convert each hypothesis from a Python list of numbers to a binary numpy array for speedier Bayesian computations later (run code to see example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of converting list hypothesis to numpy array...\n",
      "original hypothesis:\n",
      "[2, 4, 6]\n",
      "converted numpy array:\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def convert_h_list_to_numpy(h_list):\n",
    "    h_numpy = np.zeros(x_all.size)\n",
    "    h_numpy[np.array(h_list)] = 1\n",
    "    return h_numpy\n",
    "\n",
    "def generate_hypotheses(mylambda):\n",
    "    h_math,lp_math = generate_math_hypotheses(mylambda)\n",
    "    h_interval,lp_interval = generate_interval_hypotheses(mylambda)\n",
    "    H = h_math + h_interval\n",
    "    H_numpy = [convert_h_list_to_numpy(h) for h in H]\n",
    "    log_prior = np.concatenate((lp_math,lp_interval))\n",
    "    assert(np.isclose(np.sum(np.exp(log_prior)),1.0))\n",
    "    return H_numpy,log_prior\n",
    "\n",
    "print(\"Example of converting list hypothesis to numpy array...\")\n",
    "print(\"original hypothesis:\")\n",
    "h_list = [2,4,6]\n",
    "print(h_list)\n",
    "h_numpy = convert_h_list_to_numpy(h_list)\n",
    "print(\"converted numpy array:\")\n",
    "print(h_numpy[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation - Posterior and likelihood\n",
    "Now we need code to do the Bayesian computations, including a function `log_posterior` and `log-likelihood`. For probabilistic modeling, we like to compute probabilities in log-space to help avoid numerical issues such as underflow. Study the function `log_posterior` to make sure you understand how it works. Also, see the nifty `logsumexp` function ([see scipy doc](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.misc.logsumexp.html)) which is used to normalize log-probability distributions in a numerically safer way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(data,list_hypothesis,log_prior):\n",
    "    # INPUT\n",
    "    #  data : python list of observed numbers (X) \n",
    "    #  list_hypothesis : [nh length list] each hypothesis is a binary numpy array \n",
    "    #  log_prior : numpy vector [length nh] (log prior value for each hypothesis)\n",
    "    data_numpy = convert_h_list_to_numpy(data) # length nh numpy vector\n",
    "    nh = len(list_hypothesis)\n",
    "    ll = np.zeros(nh)\n",
    "    for idx,h in enumerate(list_hypothesis):\n",
    "        ll[idx] = log_likelihood(data_numpy,h)\n",
    "    lpost = ll + log_prior\n",
    "    lpost = lpost - logsumexp(lpost)\n",
    "    return lpost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 3 (10 points) </h3>\n",
    "<br>\n",
    "Fill in the missing code below to complete the `log-likelihood` function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(data_numpy, hypothesis):\n",
    "    # INPUT\n",
    "    #  data_numpy : size x_max binary numpy array (observed numbers)\n",
    "    #  hypothesis: size x_max binary numpy array (included numbers in single hypothesis)\n",
    "    # RETURN\n",
    "    #  ll : log-likelihood value (REMEMBER TO CONVERT TO NATURAL LOG (np.log()))\n",
    "    assert(hypothesis.size == data_numpy.size)\n",
    "    n_d = np.sum(data_numpy)\n",
    "    n_h = np.sum(hypothesis)\n",
    "    for i in range(data_numpy.shape[0]):\n",
    "        if data_numpy[i]==1 and hypothesis[i]==0:\n",
    "            return -np.inf \n",
    "    \n",
    "    ll=-n_d*np.log(n_h)\n",
    "    # TODO: Add your code to check whether or not the hypothesis contains all of the data.\n",
    "    #   If it does not, return -np.inf (log(0))\n",
    "\n",
    "    # TODO: Add your code to compute the log-likelihood if the hypothesis contains all of the data.\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation - Making Bayesian predictions\n",
    "We now have all the code in place to make Bayesian predictions regarding the membership of new numbers, as described by the previous equations,\n",
    "\n",
    "\\begin{equation}\n",
    "P(y \\in C\\ |\\ X) = \\sum_{h \\in H} P(y \\in C\\ |\\ h) P(h|X).\n",
    "\\end{equation}\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 4 (10 points) </h3>\n",
    "<br>\n",
    "<ul>\n",
    "    <li>Fill in the missing code below to help complete the `bayesian_predictions` function.</li>\n",
    "    <li>Use the `bayesian_predictions` function to double check your answer in Problem 2. Remember that there are only two hypotheses \"multiples of 10\" and \"even numbers\". For $X$, the numbers 10 and 30 were observed. Compute the probability that 40 and 4 are a member of the same concept as the numbers in $X$. Don't forget to convert your individual hypotheses to numpy arrays using `convert_h_list_to_numpy` </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_predictions(data_eval, data, list_hypothesis, log_prior):\n",
    "    # INPUT\n",
    "    #  data_eval : [length ne python list] of new numbers we want to check the probability of membership for\n",
    "    #     each number in data_eval is to be evaluated independently -- it's a separate 'y' in equation above\n",
    "    #  data : [python list] observed numbers (X) \n",
    "    #  list_hypothesis : python list of hypotheses, each is a binary numpy array \n",
    "    #  log_prior : numpy vector [length nh] which is the log prior value for each hypothesis\n",
    "    # \n",
    "    # RETURN\n",
    "    #  pp : numpy vector [size ne] of predicted probabilities of new numbers in data_eval (NOTE: NOT IN LOG SPACE)\n",
    "    lpost = log_posterior(data,list_hypothesis,log_prior)\n",
    "    post = np.exp(lpost) # posterior probabilities\n",
    "    h_mat = np.array(list_hypothesis) # create a [nh by x_max] numpy matrix, showing numbers in each hypothesis\n",
    "    ne = len(data_eval) # how many numbers to evaluate\n",
    "    pp = np.zeros(ne) # predicted probability of each number\n",
    "    for idx,de in enumerate(data_eval):\n",
    "        pp[idx]=np.dot(post,h_mat[:,de])\n",
    "        #TODO : Add your code here to compute predicted probabilities. Can be a single line with form \"pp[idx] = \"..\n",
    "    return pp, post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.03846154]), array([0.96153846, 0.03846154]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : Check your answers for problem 2 using the bayesian_prediction function\n",
    "h1=convert_h_list_to_numpy([10*i for i in range(1,11)])\n",
    "h2=convert_h_list_to_numpy([2*i for i in range(1,51)])\n",
    "h=[h1,h2]\n",
    "bayesian_predictions([40,4],[10,30],h,[0.5,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model and predicting human data\n",
    "Now we have all the pieces in place to run the complete number game model.\n",
    "\n",
    "First, let's described the data from participants. Tenenbaum ran eight participants in an experiment where they were provided with various sets $X$ of random positive examples from a concept. They were asked to rate the probability that each of 30 test numbers would belong to the same concept of the observed examples. \n",
    "\n",
    "The following plot shows the mean rating across the human participants for three different sets. Note that since only 30 test numbers were evaluated, and thus a value of 0 in the plot indicates missing data (rather than zero probability).\n",
    "<img src=\"images/number_game_human.jpeg\" style=\"width: 800px;\"/>\n",
    "\n",
    "Let's produce the same plots for the Bayesian concept learning model using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(x_eval,mypred):\n",
    "    mybottom = -0.1\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    print(x_eval)\n",
    "    print(mypred)\n",
    "    plt.bar(x_eval,mypred-mybottom,bottom=mybottom)\n",
    "    plt.ylim((mybottom,1.2))\n",
    "    plt.xticks(np.arange(0, x_max+1, step=4))\n",
    "    plt.yticks([0,0.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 32, 36, 41, 56, 62, 64, 87, 95, 96]\n",
      "(array([1.93947885e-01, 6.73546783e-01, 1.53175488e-01, 3.58050714e-01,\n",
      "       1.60111143e-01, 9.18110369e-02, 1.56609743e-01, 1.11888956e-01,\n",
      "       1.47850659e-01, 1.45942023e-01, 1.00000000e+00, 1.49927746e-01,\n",
      "       1.55442812e-01, 1.22744344e-01, 1.70417826e-01, 1.00488456e-01,\n",
      "       1.10708293e-01, 2.16233077e-01, 1.66277242e-01, 1.79650781e-01,\n",
      "       1.09241475e-01, 3.40106897e-01, 2.79611034e-01, 1.35704760e-02,\n",
      "       2.43728856e-01, 2.14179866e-02, 7.36701955e-01, 1.03025724e-04,\n",
      "       2.77230248e-05, 2.40748946e-01]), array([0.        , 0.01978579, 0.09892893, ..., 0.        , 0.        ,\n",
      "       0.        ]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-be819fa97219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesian_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prior_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bayesian inference, X=[16]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prob. of membership'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-e4b44c1270f7>\u001b[0m in \u001b[0;36mplot_predictions\u001b[0;34m(x_eval, mypred)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmypred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmybottom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmybottom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2405\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m         data=None, **kwargs):\n\u001b[0;32m-> 2407\u001b[0;31m     return gca().bar(\n\u001b[0m\u001b[1;32m   2408\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2338\u001b[0m                 \u001b[0myerr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_dx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2340\u001b[0;31m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[0m\u001b[1;32m   2341\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m             np.atleast_1d(x), height, width, y, linewidth)\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "H_all,log_prior_all = generate_hypotheses(mylambda=2./3)\n",
    "x_eval = [2,4,6,8,9,10]+list(range(12,23))+[24,25,26,28,32,36,41,56,62,64,87,95,96]\n",
    "\n",
    "mypred = bayesian_predictions(x_eval, [16], H_all, log_prior_all)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('Bayesian inference, X=[16]')\n",
    "plt.ylabel('prob. of membership')\n",
    "mypred = bayesian_predictions(x_eval, [16, 8, 2, 64], H_all, log_prior_all)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('Bayesian inference, X=[16, 8, 2, 64]')\n",
    "mypred = bayesian_predictions(x_eval, [16, 23, 19, 20], H_all, log_prior_all)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('Bayesian inference, X=[16, 23, 19, 20]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 5 (10 points) </h3>\n",
    "<br>\n",
    "Using the code above, produce plots the show the Bayesian model's predictions. Produce the plots for the default `mylambda = 2./3`, but also reproduce the plots below for another value of `mylambda` that shows qualitatively different results. \n",
    "<ul>\n",
    "    <li>Which value of `mylambda` seems to capture the human behavior data the best?</li>\n",
    "    <li>Comment on why the predictions change for different values of `mylambda`.</li>\n",
    "</ul>\n",
    "<br>\n",
    "Your response in the cells below should include plots for a least one new setting of lambda, and 1-2 paragraphs of discussion about how the results change as a function of `mylambda`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For mylambda=0\n",
      "[2, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 32, 36, 41, 56, 62, 64, 87, 95, 96]\n",
      "(array([5.60083334e-02, 1.24417066e-01, 2.07971682e-01, 3.10025519e-01,\n",
      "       3.69236311e-01, 4.34674357e-01, 5.86920792e-01, 6.75252915e-01,\n",
      "       7.72875008e-01, 8.80764106e-01, 1.00000000e+00, 9.04818052e-01,\n",
      "       8.18693863e-01, 7.40765475e-01, 6.70252953e-01, 6.06450585e-01,\n",
      "       5.48719815e-01, 4.49216897e-01, 4.06448891e-01, 3.67750798e-01,\n",
      "       3.01051998e-01, 2.01734096e-01, 1.35159316e-01, 8.18981939e-02,\n",
      "       1.81158565e-02, 9.85037161e-03, 8.02791211e-03, 6.21763063e-04,\n",
      "       1.67309214e-04, 1.32021121e-04]), array([0., 0., 0., ..., 0., 0., 0.]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-b9b6f396c888>:51: RuntimeWarning: divide by zero encountered in log\n",
      "  log_prior = np.log(mylambda * np.ones(n_hyp) / float(n_hyp))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-6a3187cd878c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesian_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prior_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bayesian inference, X=[16]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prob. of membership'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-e4b44c1270f7>\u001b[0m in \u001b[0;36mplot_predictions\u001b[0;34m(x_eval, mypred)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmypred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmybottom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmybottom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2405\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m         data=None, **kwargs):\n\u001b[0;32m-> 2407\u001b[0;31m     return gca().bar(\n\u001b[0m\u001b[1;32m   2408\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2338\u001b[0m                 \u001b[0myerr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_dx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2340\u001b[0;31m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[0m\u001b[1;32m   2341\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m             np.atleast_1d(x), height, width, y, linewidth)\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mylambda in [0,1./4,1./3,0.5,2./3,3./4,1]:\n",
    "    print('For mylambda={}'.format(mylambda))\n",
    "    H_all,log_prior_all = generate_hypotheses(mylambda)\n",
    "    x_eval = [2,4,6,8,9,10]+list(range(12,23))+[24,25,26,28,32,36,41,56,62,64,87,95,96]\n",
    "\n",
    "    mypred = bayesian_predictions(x_eval, [16], H_all, log_prior_all)\n",
    "    plot_predictions(x_eval,mypred)\n",
    "    plt.title('Bayesian inference, X=[16]')\n",
    "    plt.ylabel('prob. of membership')\n",
    "    mypred = bayesian_predictions(x_eval, [16, 8, 2, 64], H_all, log_prior_all)\n",
    "    plot_predictions(x_eval,mypred)\n",
    "    plt.title('Bayesian inference, X=[16, 8, 2, 64]')\n",
    "    mypred = bayesian_predictions(x_eval, [16, 23, 19, 20], H_all, log_prior_all)\n",
    "    plot_predictions(x_eval,mypred)\n",
    "    plt.title('Bayesian inference, X=[16, 23, 19, 20]')\n",
    "    plt.show()\n",
    "    print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response\n",
    "\n",
    "The value (mylambda/(1-mylambda) controls the weight. As the value of mylambda increases, the model is more mathematically justified. Humans tend to choose mylambda after observing the data. We wait to see if the mathematical hypothesis or inerval hypothesis fits the data better. \n",
    "\n",
    "Higher mylambdas give better results or data which follows mathematical hypotheses, and lower mylambdas are better for data following interval hypotheses. I may choose a mylambda around 0.5, because it captures human behavior data the best.\n",
    "\n",
    "Predictions change with mylambda because the probability of each number depends on the priors of the hypothesis, which are very dependent on mylambda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making maximum a posteriori (MAP) predictions\n",
    "As implemented above, to make proper Bayesian predictions, we marginalize (average) over all of our hypotheses weighted by our posterior belief.\n",
    "\n",
    "\\begin{equation}\n",
    "P(y \\in C\\ |\\ X) = \\sum_{h \\in H} P(y \\in C\\ |\\ h) P(h|X).\n",
    "\\end{equation}\n",
    "\n",
    "However, the summation over all hypotheses isn't always tractable (although it is in this case). A common approximation to full Bayesian inference is called maximum a posteriori (MAP) inference: making predictions based on just the best hypothesis $h^*$, as determined by its score under the posterior distribution.\n",
    "\n",
    "\\begin{equation}\n",
    "h^* = \\text{argmax}_{h \\in H} P(h^*|X).\n",
    "\\end{equation}\n",
    "\n",
    "Then, predictions are made as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "P(y \\in C\\ |\\ X) \\approx P(y \\in C\\ |\\ h^*).\n",
    "\\end{equation}\n",
    "\n",
    "In essence, we pretend that there is only one term in our hypotheses average. This can be a good approximation if just one hypothesis is dominant in the posterior. Otherwise, it can be a poor approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 6 (10 points) </h3>\n",
    "<br>\n",
    "<li>Fill in the missing code below to help complete the `MAP_predictions` function.</li></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b05bd1fb5f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mx_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m62\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m87\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAP_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prior_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MAP inference, X=[16]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-b05bd1fb5f73>\u001b[0m in \u001b[0;36mMAP_predictions\u001b[0;34m(data_eval, data, list_hypothesis, log_prior)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#TODO : Add your code here to compute MAP approximation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mde\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mde\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'post' is not defined"
     ]
    }
   ],
   "source": [
    "def MAP_predictions(data_eval, data, list_hypothesis, log_prior):\n",
    "    # INPUT\n",
    "    #  data_eval : [length ne python list] of new numbers we want to check the probability of membership for\n",
    "    #     each number in data_eval is to be evaluated independently -- it's a separate 'y' in equation above\n",
    "    #  data : [python list] observed numbers (X) \n",
    "    #  list_hypothesis : python list of hypotheses, each is a binary numpy array \n",
    "    #  log_prior : numpy vector [length nh] which is the log prior value for each hypothesis\n",
    "    # \n",
    "    # RETURN\n",
    "    #  pp : numpy vector [size ne] of predicted probabilities of new numbers in data_eval (NOTE: NOT IN LOG SPACE)\n",
    "    lpost = log_posterior(data,list_hypothesis,log_prior)\n",
    "    ne = len(data_eval) # how many numbers to evaluate\n",
    "    pp = np.zeros(ne) # predicted probability of each number\n",
    "    #TODO : Add your code here to compute MAP approximation  # ?????\n",
    "    for idx,de in enumerate(data_eval):\n",
    "        pp[idx]=np.dot(post,h_mat[:,de])\n",
    "    return pp\n",
    "\n",
    "H_all,log_prior_all = generate_hypotheses(mylambda=2./3)\n",
    "x_eval = [2,4,6,8,9,10]+list(range(12,23))+[24,25,26,28,32,36,41,56,62,64,87,95,96]\n",
    "\n",
    "mypred = MAP_predictions(x_eval, [16], H_all, log_prior_all)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('MAP inference, X=[16]')\n",
    "plt.ylabel('prob. of membership')\n",
    "mypred = MAP_predictions(x_eval, [16, 8, 2, 64], H_all, log_prior_all)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('MAP inference, X=[16, 8, 2, 64]')\n",
    "mypred = MAP_predictions(x_eval, [16, 23, 19, 20], H_all, log_prior_all)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('MAP inference, X=[16, 23, 19, 20]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 7 (5 points) </h3>\n",
    "<br>\n",
    "Using the code above, produce plots that show the model's predictions using the MAP approximation. Is MAP inference or full Bayesain inference a better account of the human behavioral data in this experiment? Why? Your answer should just be a few sentences.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR RESPONSE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 8 (10 points) </h3>\n",
    "<br>\n",
    "Discuss your general thoughts on this Bayesian model to understand human judgments in the number game. Discussion questions could include the following (as well as others):\n",
    "<ul>\n",
    "    <li>Is the model convincing? Why or why not?</li>\n",
    "    <li>Is the number game and Bayesian model relevant to more naturalistic settings for concept learning in childhood or everyday life?</li>\n",
    "    <li>Where could the hypothesis space come from?</li>\n",
    "    <li>What algorithms could people be using to approximate Bayesian inference, rather than enumerating all the hypotheses, as in the current implementation?</li>\n",
    "</ul>\n",
    "<br>\n",
    "Please write a short response in the cell below. Your response should be about two paragraphs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response\n",
    "\n",
    "The Bayesian model is somehwat convincing. It can replicate human judgements farely well when it comes to quantitative thinking, effectively combining prior knowledge with data to update beliefs. However, Bayesian modeling assumes everything to be rational which human actions are sometimes not. In fact, human actions are consistently very illogical and irrational\n",
    "\n",
    "Children learn similarly to models in that they gather more data which updates their decision-making strategy. This can alsobe observed in adults, but it is less clear as adults already have a lot of information (data).\n",
    "\n",
    "Humans don't have a hypothesis space on which to make our decisions. Humans rely on past data to make decisions, though I feel it's a stretch to call that the hypothesis space because it's so qualitative as opposed to quantitative.\n",
    "\n",
    "It would be interesting to enumerate through the most likely hypotheses instead of all of them, to approximate Bayesian inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h3> Problem 9 (20 points)</h3>\n",
    "<br>\n",
    "Here we consider a sampling-based strategy to approximate full Bayesian inference (as opposed to the cruder MAP approximation). This problem asks you to implement a \"likelihood weighted sampler\" as discussed in lecture. Review the lecture notes on importance sampling and specifically \"likelihood weighted sampling\", where we choose the approximate distribution Q to be the prior distribution over hypotheses.\n",
    "<ul>\n",
    "    <li>Fill in the missing code below to help complete the `draw_prior_samples`, `weight_samples`, and `importance_sampler_predictions` functions.</li>\n",
    "    <li>Run your likelihood weighted sampler for 2000 samples and reproduce the plots in Problem 5. Does approximate inference match the exact inference?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prior_samples(nsamp):\n",
    "    # INPUT\n",
    "    #  nsamp : number of hypotheses to be sampled from the prior\n",
    "    #\n",
    "    # RETURN\n",
    "    #  list_H : [nsamp length python list] of sampled hypotheses (each is a binary numpy vector [length x_max])\n",
    "    #\n",
    "    # TODO: Add your code to draw a list of samples (from H_all) given their prior probabilities (log_prior_all)\n",
    "    raise Exception('Replace with your code.')\n",
    "    return list_H\n",
    "\n",
    "def weight_samples(data, list_H):\n",
    "    # INPUT\n",
    "    #  data : [python list] of observed data\n",
    "    #  list_H : [nsamp length pythong list] of sampled hypotheses (each is a binary numpy vector [length x_max])\n",
    "    #     these are the sampled \"particles\" in the importance sampler\n",
    "    #\n",
    "    # Output\n",
    "    #  log_wt : numpy vector [size nsamp] log importance weight of each sample in list_H\n",
    "    #\n",
    "    # TODO: Add your code to return the log-weight of each particle\n",
    "    raise Exception('Replace with your code.')\n",
    "    return log_wt\n",
    "\n",
    "def importance_sampler_predictions(data_eval, list_H, log_wt):\n",
    "    # INPUT\n",
    "    #  data_eval : [length ne python list] of new numbers we want to evaluate the probability of membership for \n",
    "    #     each number in data_eval is to be evaluated independently (as in bayesian_predictions function)\n",
    "    #  list_H : nsamp length pythong list] of sampled hypotheses (each is a binary numpy vector [length x_max])\n",
    "    #  log_wt : numpy vector [size nsamp] log importance weight of each sample in list_H\n",
    "    # \n",
    "    # RETURN\n",
    "    #  pp : numpy vector [size ne] of predicted probabilities of new numbers  (NOTE: NOT IN LOG SPACE)\n",
    "    wt = np.exp(log_wt)\n",
    "    h_mat = np.array(list_H) # create a [nsamp by x_max] numpy matrix, showing numbers in each hypothesis/sample\n",
    "    ne = len(data_eval) # how many numbers to evaluate\n",
    "    pp = np.zeros(ne) # predicted probability of each number\n",
    "    for idx,de in enumerate(data_eval):\n",
    "        #TODO : Add your code here/ Can be a single line with form \"pp[idx] = \"..\n",
    "        raise Exception('Replace with your code.')\n",
    "    return pp\n",
    "    \n",
    "nsamples_importance = 2000 # number of samples\n",
    "plt.figure()\n",
    "list_H_importance = draw_prior_samples(nsamples_importance) # prior samples can be re-used across queries\n",
    "log_wt_importance = weight_samples([16],list_H_importance)\n",
    "mypred = importance_sampler_predictions(x_eval, list_H_importance, log_wt_importance)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('X=[16] (importance sampler)')\n",
    "plt.ylabel('prob. of membership')\n",
    "\n",
    "log_wt_importance = weight_samples([16, 8, 2, 64],list_H_importance)\n",
    "mypred = importance_sampler_predictions(x_eval, list_H_importance, log_wt_importance)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('X=[16, 8, 2, 64] (importance sampler)')\n",
    "\n",
    "log_wt_importance = weight_samples([16, 23, 19, 20],list_H_importance)\n",
    "mypred = importance_sampler_predictions(x_eval, list_H_importance, log_wt_importance)\n",
    "plot_predictions(x_eval,mypred)\n",
    "plt.title('X=[16, 23, 19, 20] (importance sampler)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
